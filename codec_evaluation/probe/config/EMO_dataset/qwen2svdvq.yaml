mode: quantized_emb
sample_rate: 44100
target_sec: 30
num_outputs: 2
probe_ckpt_dir: /home/lr/project/Codec-Evaluation/codec_eval/EMO_dataset/ckpt/qwen2svdvq/${mode}
seed: 666
codec_name: qwen2svdvq
task: regression
save_result: null

trainer:
  _target_: pytorch_lightning.Trainer
  accelerator: gpu
  devices: [5, 6]
  precision: 32
  max_epochs: 300
  check_val_every_n_epoch: 5
  limit_val_batches: 1.0
  log_every_n_steps: 5
  val_check_interval: 1.0

data:
  _target_: codec_evaluation.probe.dataset.EMO_dataset.EMOdataModule
  dataset_args:
    sample_rate: ${sample_rate}
    target_sec: ${target_sec}
    is_mono: True
    is_normalize: False
    audio_dir: /sdb/data1/music/mix_music/marble_dataset/data/EMO/emomusic/wav
    meta_dir: /sdb/data1/music/mix_music/marble_dataset/data/EMO/emomusic
  codec_name: ${codec_name}
  train_batch_size: 32
  valid_batch_size: 1
  test_batch_size: 32
  train_num_workers: 10
  valid_num_workers: 4
  test_num_workers: 4

model:
  _target_: codec_evaluation.probe.model.lit_prober.Prober
  codec_name: ${codec_name}
  sample_rate: ${sample_rate}
  mode: ${mode}
  task: ${task}
  codec_dim: 128
  num_outputs: ${num_outputs}
  probe_model_builder:
    _target_: codec_evaluation.probe.model.EMO_dataset.model.EMOProber
    _partial_: true
    num_outputs: ${num_outputs}
    drop_out: 0.1
    channel_reduction: 16
    target_T: 750
    padding: 1
    kernel_size: 3
    stride: 1
  target_sec: ${target_sec}
  model_ckpt_dir: /home/lr/project/Echodec/sfm/train/whisperVQ_train/experiments/Qwen2_SVDVQ_128_128_code_128_ILLUMEloss/checkpoints/model_epoch=epoch=24_val_loss=val_loss=0.0000.ckpt

  optimizer_builder:
    _target_: torch.optim.AdamW
    _partial_: true
    lr: 1e-4
    betas: [0.8, 0.99]
    eps: 1e-5
    weight_decay: 0.08
    
  lr_scheduler_builder:
    _target_: torch.optim.lr_scheduler.LambdaLR
    _partial_: true
    lr_lambda:
      _target_: codec_evaluation.utils.schedule.get_cosine_schedule_with_warmup_lr_lambda
      _partial_: true
      num_warmup_steps: 10
      num_training_steps: 10000
      final_lr_ratio: 0.2

callbacks:
  learning_rate_monitor:
    _target_: pytorch_lightning.callbacks.LearningRateMonitor
    logging_interval: step

  rich_progress_bar:
    _target_: pytorch_lightning.callbacks.RichProgressBar

  model_summary:
    _target_: pytorch_lightning.callbacks.ModelSummary
    max_depth: 1

  model_checkpoint:
    _target_: pytorch_lightning.callbacks.ModelCheckpoint
    monitor: valid_loss
    dirpath: ${probe_ckpt_dir}
    every_n_epochs: 1
    mode: min
    save_top_k: 1
    save_last: False
    filename: ${codec_name}_${mode}_{epoch}-{valid_loss:.4f}
    verbose: True

tensorboard:
  _target_: pytorch_lightning.loggers.TensorBoardLogger
  save_dir: /home/lr/project/Codec-Evaluation/codec_eval/EMO_dataset/tb_log
  name: ${codec_name}_${mode}_svd_128_128_ILLUMEloss
  log_graph: true
