# Path: benchmark/tasks/MTG/MTGGenre_base_config.yaml
# Description: 
#   Base config for MTGGenre. It show case the usage of probing MERT-v1-95M model on MTGGenre dataset.

dataset:
  dataset: MUSDB18
  input_type: audio # [audio, feature]
  input_dir: 
  metadata_dir: 


model:    
  upstream_structure:
    feature_extractor:
      pretrain:
        !include benchmark/models/musichubert_hf/MERT-v1-95M.yaml
      force_half: false
      layer: null # null means save features from all layers
      reduction: none # [mean, max, min, none]

  downstream_structure:
    components:
      - name: feature_selector
        layer: 7 # [all, 0, 1, 2, ..., $n_tranformer_layer]
        # weighted sum is only effective when layer is set to all
        normalized_weight_sum: true
      
      - name: lstm
        hidden_size: 512
        num_layers: 1
        bidirectional: true
        dropout_p: 0.2
        num_outputs: 4

      - name: mlp
        hidden_layer_sizes: [512]
        dropout_p: 0.2
        num_outputs: 87


trainer: 
  # pytorch lightning trainer args
  auto_lr_find: false
  accelerator: gpu
  devices: 1
  strategy: null # [null, ddp]
  precision: 16
  accumulate_grad_batches: 1
  fast_dev_run: false
  log_every_n_steps: 50
  max_epochs: 100 
  num_nodes: 1

  # custom args
  seed: 1234
  eval_only: false
  paradigm: probe # [probe, finetune]


dataloader:
  num_workers: 6
  batch_size:
    train: 64
    valid: 1
    test: 1


optimizer:
  name: torch.optim.Adam
  l2_weight_decay: 0.0
  lr: 1e-3


scheduler:
  lr_scheduler_patience: 3
  earlystop_patience: 10


loss:
  loss_weight: null


logger:
  wandb_off: false # turn off wandb
  wandb_proj_name: Eval_MTGGenre_probing
  wandb_run_name: null
  wandb_dir: data
  wandb_sweep: false
  monitor: valid_aucroc


checkpoint:
  save_best_to: null
  eval_ckpt_path: null


hp_search:
  enable: false
  framework: ray
  technique: grid_search # [grid_search, random_search, bayesian_optimization, hyperband, asha]
  search_list: 
    - name: lr
      space: [1e-2, 5e-3, 1e-3, 5e-4, 1e-4]

